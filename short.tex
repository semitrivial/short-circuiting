\documentclass[runningheads]{llncs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathrsfs}
% \smartqed  % flush right qed marks, e.g. at end of proof
% \usepackage{graphicx}

\newcommand{\myclaim}[1]{\textbf{Claim #1:}}
\def\myulcorner{\mathord{\ulcorner}}
\def\myurcorner{\mathord{\urcorner}}

\pagenumbering{gobble}

\begin{document}

\title{Short-circuiting the definition of mathematical knowledge for an AGI
%\thanks{}
}

%\titlerunning{Short-circuiting the definition of knowledge}

\author{Samuel Allen
Alexander\inst{1}\orcidID{0000-0002-7930-110X}}

\institute{The U.S.\ Securities and Exchange Commission
\email{samuelallenalexander@gmail.com}
\url{https://philpeople.org/profiles/samuel-alexander/publications}}


\maketitle

\begin{abstract}
Fill this in.
\keywords{AGI \and machine knowledge \and Moore's paradox}
\end{abstract}

\section{Introduction}

It is difficult to define knowledge, or what it means to know something.
In Plato's dialogs, again and again Socrates asks people to define
knowledge\footnote{Perhaps the best example being in the \emph{Theaetetus}
\cite{theaetetus}.}, and no-one ever succeeds. Neither have philosophers
reached consensus even in our own era (see \cite{sep-knowledge-analysis}).

At the same time, the problem is often brushed aside as something only
philosophers care about: pragmatists rarely spend time
on this sort of debate. One exceptional area where the question becomes
important even to pragmatists is in the area of Artificial General Intelligence
(AGI). In AGI research, these old philosophical conundrums rear their ugly
once more.

In this paper, we narrow down the question ``what is knowledge'' and offer
a simple answer within that narrow context:
we propose a definition of what it means for a suitably idealized AGI to know
a mathematical fact. Our proposed definition is short and sweet: we say that
an AGI knows a mathematical fact (in some standard mathematical language $\mathscr L$)
if and only if that fact would be among the statements which that AGI would
enumerate if that AGI were commanded:
``Enumerate, in the language $\mathscr L$, every mathematical fact which
is both expressible in $\mathscr L$ and part of your own mathematical knowledge.''

Our proposed definition is not directly intended
for methodological purposes---it would not
be helpful in the quest to construct an AGI. Instead, it is intended for
theoretical purposes of understanding the properties of AGI.


\section{Idealized AGIs}

In this paper, we approach AGI using what
Goertzel \cite{goertzel2014artificial} calls
the Universalist Approach:
we adopt ``...an idealized case of AGI, similar to
assumptions like the frictionless plane in physics'', hoping that by
understanding this ``simplified special
case, we can use the understanding we've gained to address more realistic
cases.'' We make the following assumptions about an AGI $X$
(where $\mathscr L$ is some standard mathematical language):
\begin{itemize}
  \item (Truthfulness) Whatever $\mathscr L$-statements $X$ enumerates
  when commanded to enumerate the $\mathscr L$-statements that $X$ knows,
  all such statements are true.
  \item (Obedience) When commanded to enumerate the $\mathscr L$-statements that $X$ knows,
  $X$ will obey the command: $X$ will enumerate exactly the
  $\mathscr L$-statements that $X$ knows (according to $X$'s own internal definition
  of knowledge, whatever that may be).
\end{itemize}

Note that in our \emph{Obedience} assumption, we do not require the AGI to use
the same definition of knowledge that we are proposing in this paper. We allow
the AGI to have whatever definition of knowledge it likes.

The \emph{Truthfulness} and \emph{Obedience} assumptions would be inappropriate
for human agents $X$, who make mathematical
mistakes, and who tend to hold unfounded beliefs and claim them as knowledge,
and who might tend to resist tedious tasks such as enumerating endless lists of
mathematical statements. But arguably these assumptions are plausible for a
sufficiently idealized AGI. Such an AGI can presumably perform calculations with
no risk of mechanical error. Such an AGI is presumably free of the human
psychological quirks which cause humans to cling to unfounded beliefs (especially
since we are only considering mathematical statements, not contingent on
the physical world). And such an AGI should have unlimited patience and have no
problem tediously enumerating mathematical statements as long as electricity is
available.


\section{An elegant definition of mathematical knowledge}

If $X$ is an idealized AGI satisfying the assumptions of \emph{Truthfulness}
and \emph{Obedience} from the previous section, we define the mathematical
knowledge of $X$ as follows (where $\mathscr L$ denotes a standard mathematical
language).

\begin{definition}
\label{maindef}
  For any $\mathscr L$-sentence $\phi$, we say that $X$ knows $\phi$ if and only
  if $X$ would eventually list $\phi$ amount the $\mathscr L$-statements which $X$
  would list if $X$ were commanded:
  ``Enumerate, in the language $\mathscr L$, every mathematical fact which
  is both expressible in $\mathscr L$ and part of your own mathematical knowledge.''
\end{definition}

One of the strengths of Definition \ref{maindef} is that it is uniform across
different AGIs: many different AGIs might internally operate based on different
definitions of knowledge, but Definition \ref{maindef} works equally well for
all these different AGIs irrespective of those different internal knowledge
definitions\footnote{This is reminiscent of Elton's proposal that instead of
trying to interpret an AI's outputs by focusing on specific low-level details
of a neural network, we should instead let the AI explain itself \cite{elton}.}.

Although Definition \ref{maindef} may differ significantly from a particular AGI
$X$'s own internal definition of knowledge, the following theorem states that
materially the two definitions have the same result.

\begin{theorem}
\label{sentenceequivalence}
  Suppose $X$ is an AGI satisfying Truthfulness and Obedience, and let $\mathscr L$
  be a standard mathematical language. For any $\mathscr L$-sentence $\phi$, the following
  are equivalent:
  \begin{enumerate}
    \item $X$ is
    considered to know $\phi$ (based on Definition \ref{maindef}).
    \item
    $X$ is considered to know $\phi$ (based on $X$'s own inernal definition of
    knowledge).
  \end{enumerate}
\end{theorem}

\begin{proof}
  By Definition \ref{maindef}, (1) is equivalent to the statement that $X$ would
  include $\phi$ in the list which $X$ would output if $X$ were commanded to output
  all the $\mathscr L$-sentences that $X$ knows. By Obedience, $X$ would output
  $\phi$ in that list if and only if (2).
\end{proof}

In the next subsection we will strengthen Theorem \ref{sentenceequivalence} by
considering it through the lens of quantified modal logic.

\subsection{Quantified modal logic}

In order to strengthen Theorem \ref{sentenceequivalence}, we would like to work
in quantified modal logic. We begin with some standard definitions.

(Fill this in)

\begin{definition}
  Suppose $\mathscr L_0$ is a standard first-order mathematical language
  extending PA,
  and let $\mathscr L$ consist
  of $\mathscr L_0$ together with a knowledge operator $K$. Suppose
  $\mathscr M_0$
  is an $\mathscr L_0$-model with standard first-order part.
  We define two extensions of
  $\mathscr M_0$ to $\mathscr L$ as follows.
  \begin{itemize}
    \item
    (The External Extension)
    Let $\mathscr M^{ext}$ be the $\mathscr L$-model with universe $\mathbb N$,
    agreeing with $\mathscr M_0$ on $\mathscr L_0$, and interpreting $K$ as follows.
    For any $\mathscr L_0$-formula $\phi$ and assignment $s$,
    $\mathscr M^{ext}\models K(\phi)[s]$ if and only if
    $X$ knows $\phi^s$ (according to Definition \ref{maindef}).
    \item
    (The Internal Extension)
    Let $\mathscr M^{int}$ be the $\mathscr L$-model with universe $\mathbb N$,
    agreeing with $\mathscr M_0$ on $\mathscr L_0$, and interpreting $K$ as follows.
    For any $\mathscr L_0$-formula $\phi$ and assignment $s$,
    $\mathscr M^{int}\models K(\phi)[s]$ if and only if
    $X$ knows $\phi^s$ (according to $X$'s internal definition of knowledge).
  \end{itemize}
\end{definition}


\begin{theorem}
  For any $\mathscr L_0$, $\mathscr L$, $\mathscr M_0$ as in Definition
  \ref{internalexternal}, $\mathscr M^{ext}=\mathscr M^{int}$.
\end{theorem}

\bibliographystyle{splncs04}
\bibliography{short}

\end{document}