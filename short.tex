\documentclass[runningheads]{llncs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathrsfs}
% \smartqed  % flush right qed marks, e.g. at end of proof
% \usepackage{graphicx}

\newcommand{\myclaim}[1]{\textbf{Claim #1:}}
\def\myulcorner{\mathord{\ulcorner}}
\def\myurcorner{\mathord{\urcorner}}

\pagenumbering{gobble}

\begin{document}

\title{Short-circuiting the definition of mathematical knowledge for an
Artificial General Intelligence
%\thanks{}
}

\titlerunning{Short-circuiting the definition of mathematical knowledge for an AGI}

\author{Samuel Allen
Alexander\inst{1}\orcidID{0000-0002-7930-110X}}

\institute{The U.S.\ Securities and Exchange Commission
\email{samuelallenalexander@gmail.com}
\url{https://philpeople.org/profiles/samuel-alexander/publications}}


\maketitle

\begin{abstract}
We propose that, for the purpose of studying theoretical properties of
the knowledge of an agent with Artificial General Intelligence (that is, 
the knowledge of an AGI),
a pragmatic way to define such an agent's knowledge is as follows.
We declare the AGI to know a certain statement
(in a given mathematical language) if and only if, when commanded
(in plain English) to enumerate all the statements that it knows in
said language, said AGI
would include said statement in the resulting enumeration.
This definition is non-circular because an AGI, being capable of
practical English communication, is capable of understanding the everyday
English word ``know'' independently of how any philosopher formally
defines knowledge.
This elegantly solves the problem that different AGIs may have
very different internal knowledge definitions and yet we want
to be able to study knowledge of AGIs in general, without having
to study different AGIs separately just because they have separate
internal knowledge definitions. Finally, we suggest how this
definition of AGI knowledge can be used as a bridge which could
allow the AGI research community to import certain abstract results
about mechanical knowing agents from mathematical logic.
\keywords{AGI \and machine knowledge}
\end{abstract}

\section{Introduction}

It is difficult to define knowledge, or what it means to know something.
In Plato's dialogs, again and again Socrates asks people to define
knowledge\footnote{Perhaps the best example being in the \emph{Theaetetus}
\cite{theaetetus}.}, and no-one ever succeeds. Neither have philosophers
reached consensus even in our own era (see \cite{sep-knowledge-analysis}).

At the same time, the problem is often brushed aside as something only
philosophers care about: pragmatists rarely spend time
on this sort of debate. One exceptional area where the question becomes
important even to pragmatists is in the area of Artificial General Intelligence
(AGI). In AGI research, these old philosophical conundrums rear their ugly heads
once more.

In this paper, we narrow down the question ``what is knowledge'' and offer
a simple answer within that narrow context:
we propose a definition of what it means for a suitably idealized AGI to know
a mathematical sentence\footnote{By a \emph{sentence}, we mean a formula with
no free variables. Thus, $x^2>0$ is not a sentence, but
$\forall x (x^2>0)$ is.}. Our proposed definition is short and
sweet: we say that
an AGI knows a mathematical sentence (in some standard mathematical language $\mathscr L$)
if and only if that sentence would be among the sentences which that AGI would
enumerate if that AGI were commanded:
``Enumerate, in the language $\mathscr L$, every mathematical sentence which
is both expressible in $\mathscr L$ and part of your own mathematical knowledge.''
Note that this is non-circular because an AGI, being capable of practical English
communication, is therefore capable of understanding the everyday English word
``know'' in the above command, independently of how any philosopher formally
defines knowledge. We discuss this further in Subsection \ref{noncircularsubsection}.

Our proposed definition is not directly intended
for methodological purposes---it would not
directly be helpful in the quest to construct an AGI. Instead, it is intended for
the purpose of understanding the properties of AGI (some of which
we discuss in Section \ref{appsection}). We hope that a better
understanding of theoretical properties of AGIs will indirectly help in the eventual
creation of same.

The structure of this paper is as follows.
\begin{itemize}
  \item In Section \ref{agisection} we discuss the AGIs for whose knowledge we are
  attempting to propose a definition.
  \item In Section \ref{mainsection} we propose a knowledge definition for
  AGIs for sentences in some standard mathematical language.
  \item In Section \ref{quantifiedsection} we extend our knowledge definition
  to formulas with free variables (when the
  language in question is arithmetical).
  \item In Section \ref{appsection} we use this knowledge definition as a bridge
  to allow some results from mathematical logic to inform AGI.
  \item In Section \ref{conclusionsection} we summarize and make concluding remarks.
\end{itemize}

\section{Idealized AGIs}
\label{agisection}

In this paper, we approach AGI using what
Goertzel \cite{goertzel2014artificial} calls
the Universalist Approach:
we adopt ``...an idealized case of AGI, similar to
assumptions like the frictionless plane in physics'', hoping that by
understanding this ``simplified special
case, we can use the understanding we've gained to address more realistic
cases.''

We do not have a formal definition for what an AGI is, but whatever it is,
we assume an AGI is a deterministic machine
which repeatedly reads sensory input from its environment and outputs
English words based on what sensory inputs it has received so far.
When we say that this AGI is a ``deterministic machine'', we mean that
said outputs (considered as a function of said inputs) could be computed
by a Turing machine. We further assume the AGI can understand English
commands and is capable of practical English communication. Thus, if
we were to command the AGI in English, ``Tell us the value of $1+1$'',
the AGI would respond in English and reply ``$2$'', or ``$1+1=2$'',
or something along those lines.

We assume an AGI is capable of everyday English discussions
which would cause no difficulty to a casual English speaker, even if
these discussions involve topics, such as ``knowledge'', which
might be philosophically tricky. A casual English speaker does not get
bogged down in philosophical questions about the nature of knowledge
just in order to answer a question like ``Do you know that $1+1=2$?'',
and therefore neither should our AGI.

We also assume an AGI is better than a casual English speaker in certain ways.
We assume an AGI would have no objections to performing exceedingly tedious
tasks indefinitely, if so commanded. If we asked a casual English speaker to
begin computing and reciting all the prime numbers until further notice, and
then we waited silently forever to hear the results, said human would eventually
get tired of the endless tedium and would disobey our command (not to mention
the fact that they might make arithmetic errors along the way). We assume an AGI
has no such limitations and would happily compute and recite prime numbers for
all eternity, if so commanded---and with no arithmetic errors, too. Of course,
in reality the AGI would eventually run out of memory, or perish in the heat
death of the universe, etc., but we are speaking of idealized AGI here and we
intentionally ignore such possibilities, in the same way a Turing machine is
assumed to have infinite tape and infinite time to run.


\section{An elegant definition of mathematical knowledge}
\label{mainsection}

Before getting to our knowledge definition for AGIs, we need the following
preliminary definition.

\begin{definition}
\label{stdmathematicallanguagedefn}
By a \emph{standard mathematical language}, we mean a mathematical language for which an
intended interpretation is implicitly understood.
\end{definition}

For example, the
language of Peano Arithmetic is a standard mathematical language, the obvious
intended interpretation being the model with universe $\mathbb N$ which
interprets the arithmetical symbols of Peano Arithmetic in the usual ways.
Presumably an AGI suitably familiar with the mathematical literature should
be aware of this intended interpretation for Peano Arithmetic.

Armed with Definition \ref{stdmathematicallanguagedefn}, we are ready to state
our definition of knowledge for AGIs.
See Subsection \ref{noncircularsubsection} for a discussion of the non-circularity
of the following definition.

\begin{definition}
\label{maindef}
  Let $X$ be an AGI and let $\mathscr L$ be a standard mathematical language.
  For any $\mathscr L$-sentence $\phi$, we say that $X$
  knows $\phi$ if and only
  if $X$ would eventually list $\phi$ among the $\mathscr L$-sentences which $X$
  would list if $X$ were commanded:
  ``Enumerate, in the language $\mathscr L$, every sentence,
  expressible in $\mathscr L$, which you know.''
\end{definition}

Note that Definition \ref{maindef} is non-circular because
the AGI is capable (see Section \ref{agisection}) of practical English
communication, including that involving everyday English words such as
the word ``know'', independently of how any philosophers formally
define things. More on this in Subsection \ref{noncircularsubsection}.


One of the strengths of Definition \ref{maindef} is that it is uniform across
different AGIs: many different AGIs might internally operate based on different
definitions of knowledge, but Definition \ref{maindef} works equally well for
all these different AGIs regardless of those different internal knowledge
definitions\footnote{This is reminiscent of Elton's proposal that instead of
trying to interpret an AI's outputs by focusing on specific low-level details
of a neural network, we should instead let the AI explain itself \cite{elton}.}.

Although Definition \ref{maindef} may differ significantly from a particular AGI
$X$'s own internal definition of knowledge, the following theorem states that
materially the two definitions have the same result.

\begin{theorem}
\label{sentenceequivalence}
  Suppose $X$ is an AGI, and let $\mathscr L$
  be a standard mathematical language. For any $\mathscr L$-sentence $\phi$, the following
  are equivalent:
  \begin{enumerate}
    \item $X$ is
    considered to know $\phi$ (based on Definition \ref{maindef}).
    \item
    $X$ is considered to know $\phi$ (based on $X$'s own internal understanding of
    knowledge).
  \end{enumerate}
\end{theorem}

\begin{proof}
  By Definition \ref{maindef}, (1) is equivalent to the statement that $X$ would
  include $\phi$ in the list which $X$ would output if $X$ were commanded to output
  all the $\mathscr L$-sentences that $X$ knows. Since $X$ is obedient, $X$ would output
  $\phi$ in that list if and only if (2).
\end{proof}

\begin{corollary}
(Well-definedness) Suppose $\mathscr L_1$ and $\mathscr L_2$ are two
standard mathematical languages and $\phi$ is a formula of them
(in other words, every symbol occurring in $\phi$ is in both $\mathscr L_1$
and $\mathscr L_2$). If $X$ is an AGI, then $X$ knows $\phi$ (according to
Definition \ref{maindef} with language $\mathscr L_1$) if and only if
$X$ knows $\phi$ (according to Definition \ref{maindef} with language
$\mathscr L_2$).
\end{corollary}

\begin{proof}
  By Theorem \ref{sentenceequivalence}, both statements are equivalent to
  $X$ knowing $\phi$ according to $X$'s own internal understanding of
  knowledge.
\end{proof}

\subsection{Non-Circularity of Definition \ref{maindef}}
\label{noncircularsubsection}

Definition \ref{maindef} is non-circular because an AGI's response to an English
command only depends on how the AGI understands the words in that command, not
on how \emph{we} understand the words in that command. Recall from Section \ref{agisection}
that we are assuming an AGI is a deterministic machine which outputs English words
based on sensory inputs from its environment. Those outputs depend \emph{only} on those
environmental inputs, and not on any decisions made by philosophers.

If the reader wants to further convince themselves of the non-circularity of Definition
\ref{maindef}, we need only point out that the apparent circularity would disappear if
we changed Definition \ref{maindef} to define what it means for $X$ to ``grok'' sentence
$\phi$, rather that to ``know'' sentence $\phi$ (without changing the command itself).
In other words, we could define that $X$ ``groks'' $\phi$ if and only if $X$ would include
$\phi$ in the list of sentences that would result if $X$ were commanded,
``Enumerate, in the language $\mathscr L$, every sentence,
  expressible in $\mathscr L$, which you know.''
This would make the non-circularity clearer, because the word ``grok'' does not appear
anywhere in the definition. But the circularity of the definition should not depend on
what word we assign to the definee.

For the sake of completion, we will further illustrate the non-circularity of
Definition \ref{maindef} with three examples.
\begin{itemize}
  \item
  (The color blurple) Bob could (without Alice's awareness) define ``blurple'' to be the
  color of the card
  which Alice would choose if Bob were to run up to Alice, present her a red card
  and a blue card, and demand: ``Quick, choose the blurple card! Do it now, no time
  for questions!'' There is nothing circular about this, because Alice's choice
  cannot depend on a definition which Alice is unaware of.
  \item
  (Bound variables) In mathematical logic, it is perfectly legal and non-circular to
  define $x$ to be the unique element of $\mathbb N$ satisfying the formula
  \[(x=0)\wedge \exists x(x=1).\]
  This defines $x$ as $0$. The subformula
  $\exists x(x=1)$ is true regardless of which formula this subformula is a subformula of.
  \item
  (Zero to the zero) If asked to compute $0^0$, some calculators output $1$, and some
  output an error message or say the result is undefined\footnote{Which is incorrect---see
  \cite{knuth}.}. For any calculator $X$, it
  would be perfectly non-circular to define ``the $0^0$ of $X$'' to be the output which
  $X$ outputs when asked to compute $0^0$. Said output is pre-programmed into the
  calculator; the calculator does not read the user's mind in order to base its answer
  on any definitions that exist there.
\end{itemize}

\subsection{Languages with Knowledge Operators}

Definition \ref{maindef} is particularly interesting when $\mathscr L$ itself
contains an operator for the agent's knowledge. An example of such a language would be
the language of Epistemic Arithmetic (or EA) from \cite{shapiro}, which consists of the
language of Peano Arithmetic with the addition of an operator $K$ for knowledge:
$K(1+1=2)$ should be read as something like
``I know $1+1=2$'' or ``the knower knows $1+1=2$''. In the context of this paper,
if $\mathscr L_0$ is a standard mathematical language, and if $\mathscr L$ is obtained
from $\mathscr L_0$ by the addition of a knowledge operator $K$, then we also
consider $\mathscr L$ to be a standard mathematical language. The intended model
of $\mathscr L$ shall have the same universe and interpretation of
$\mathscr L_0$-symbols as the intended model of $\mathscr L_0$. As for $K$,
the intended interpretation (by an AGI $X$) of a formula $K(\phi)$ shall be
that $X$ knows $\phi$ (according to the AGI's internal definition of knowledge).

\begin{example}
Applying Definition \ref{maindef} to the language of EA,
we consider an AGI $X$ to know $K(1+1=2)$ if and only if that AGI would output
$K(1+1=2)$ when commanded to output all sentences that $X$ knows in the language of
EA. By the intended interpretation of
EA, $X$ would (when so commanded)
output $K(1+1=2)$ if and only if $X$ knows that he knows $1+1=2$.
\end{example}

\section{Quantified Modal Logic}
\label{quantifiedsection}

Definition \ref{maindef} only addresses sentences with no free variables.
For suitable languages, we will extend this to formulas which possibly include
free variables. Here, we are essentially adapting a trick from
Carlson \cite{carlson}.

\begin{definition}
  A standard mathematical language $\mathscr L$ is said to be \emph{arithmetical}
  if the following requirements hold.
  \begin{enumerate}
    \item $\mathscr L$ contains all the symbols of Peano Arithmetic.
    \item $\mathscr L$'s intended model has universe $\mathbb N$ and interprets
    the symbols of Peano Arithmetic in the usual ways.
  \end{enumerate}
\end{definition}

\begin{definition}
  If $\mathscr L$ is arithmetical, then we define so-called \emph{numerals}, which
  are $\mathscr L$-terms, one numeral $\overline n$ for each natural number $n\in\mathbb N$,
  by induction: $\overline 0$ is defined to be $0$ (the constant symbol for zero from
  Peano Arithmetic) and
  for every $n\in\mathbb N$, $\overline{n+1}$ is defined to be $S(\overline n)$
  (where $S$ is the successor symbol from Peano Arithmetic).
\end{definition}

For example, the numeral $\overline 5$ is the term $S(S(S(S(S(0)))))$.

\begin{definition}
  If $\mathscr L$ is arithmetical and $\phi$ is an $\mathscr L$-formula (with free variables
  $x_1,\ldots,x_k$),
  and if $s$ is an assignment mapping variables to natural numbers, then we define $\phi^s$
  to be the sentence
  \[
    \phi(x_1|\overline{s(x_1)})(x_2|\overline{s(x_2)})\cdots (x_k|\overline{s(x_k)})
  \]
  obtained by substituting for each free variable $x_i$ the numeral $\overline{s(x_i)}$
  for $x_i$'s value according to $s$.
\end{definition}

\begin{example}
  Suppose $s(x)=0$, $s(y)=1$, and $s(z)=3$. Then
  \[
  ((z>y+x) \wedge \forall x(K(z>y+x-x)))^s
  \]
  is defined to be
  \[
  ((\overline 3 > \overline 1+\overline 0)
  \wedge \forall x( K( \overline 3 > \overline 1 + x - x ) ))
  \]
  (note that the numeral is not substituted for the later occurrences of $x$ because
  these are bound by the $\forall x$ quantifier).
\end{example}

\begin{definition}
\label{maindefextension}
  If $\mathscr L$ is arithmetical, $\phi$ is any $\mathscr L$-formula,
  and $s$ is any assignment mapping variables to $\mathbb N$,
  we say that $X$ knows $\phi$ (according to $s$) if and only if
  $X$ knows $\phi^s$ according to Definition \ref{maindef}.
\end{definition}

Armed with Definition \ref{maindefextension}, the Tarskian notion
\cite{sep-tarski-truth} of
truth can be extended to a complete semantics for
knowledge in any arithmetical language with exactly one knowledge operator $K$.

\begin{example}
  Assume an AGI $X$ is clear from context.
  Suppose $\phi$ is a formula of one free variable $x$, in the language of EA,
  which expresses ``the $x$th Turing machine eventually halts''. Suppose we want to
  assign a truth value to the formula $\exists x (\neg K(\phi)\wedge \neg K(\neg\phi))$.
  \begin{itemize}
  \item Following Tarski, we should declare $\exists x (\neg K(\phi)\wedge\neg K(\neg \phi))$
  is true if and only if there is some assignment $s$ mapping variables to $\mathbb N$
  such that both $K(\phi)$ and $K(\neg\phi)$ are false according to $s$.
  \item By Definition \ref{maindefextension}, this is the case if and only if
  there is some $s$ such that
  $X$ does not know $\phi^s$ and $X$ does not know $\neg\phi^s$
  (according to Definition \ref{maindef}).
  \item
  This is the case if and only if there is some $s$ such that $X$ would not
  list $\phi^s$ nor $\neg\phi^s$ if $X$ were commanded
  to enumerate his own knowledge in the language of EA.
  \item
  Since $\phi$ has just one free variable $x$, it follows that the above is equivalent to:
  there is some $n\in\mathbb N$ such that $X$ would not list $\phi(x|\overline n)$
  nor $\neg\phi(x|\overline n)$
  if $X$ were commanded as above.
  \end{itemize}
\end{example}

\section{Knowledge formulas}
\label{appsection}

In this section, we will look at some formulas about knowledge and interpret them in the
context of AGI in terms of Definitions \ref{maindef} and \ref{maindefextension}.

\begin{example}
  (Basic axioms of knowledge) The following axiom schemas, in the language
  of EA, are taken from Carlson \cite{carlson}
  (we restrict them to sentences for purposes of simplicity).
  \begin{itemize}
    \item (E1) $K(\phi)$ whenever $\phi$ is valid (i.e., a tautology).
    Interpreted for an AGI $X$ using Definition \ref{maindef}, this becomes:
    ``If commanded to enumerate his knowledge in EA, $X$ will include
    all that language's tautologies in the resulting list.'' This is plausible
    because the set of tautologies in a given computable language is computable,
    and an AGI should have no problem enumerating them.
    \item (E2) $K(\phi\rightarrow\psi)\rightarrow K(\phi)\rightarrow K(\psi)$.
    This becomes: ``If commanded to enumerate his knowledge in EA,
    if $X$ would include $\phi\rightarrow\psi$ and if $X$ would also include
    $\phi$, then $X$ would also include $\psi$.'' This is plausible because
    an AGI should certainly be capable of basic logical reasoning.
    \item (E3) $K(\phi)\rightarrow\phi$. This becomes: ``If commanded to enumerate
    his knowledge in EA, the resulting statements $X$ enumerates
    will be true.'' This is plausible since knowledge is widely regarded as
    having truthfulness as one of its requirements. Truthfulness is not a
    requirement in the definition proposed in this paper, but for any particular
    AGI, truthfulness is probably a requirement of that AGI's internal definition
    of knowledge. There is no need to worry about the AGI being misinformed about
    contingent facts about the physical world, because EA is a purely mathematical
    language in which no such contingent facts are expressible.
    \item (E4) $K(\phi)\rightarrow K(K(\phi))$. This becomes: ``If commanded to
    enumerate his knowledge in EA, if $X$ would list $\phi$,
    then $X$ would also list $K(\phi)$.'' This is plausible because presumably
    when $X$ enumerates $\phi$ in response to the command, $X$ should in some sense
    understand why he is enumerating $\phi$, namely because he knows $\phi$---so $X$
    should therefore know that he knows $\phi$.
  \end{itemize}
\end{example}

\begin{example}
\label{smtexample}
    (Reinhardt's strong mechanistic thesis
    \cite{reinhardt1985absolute} \cite{reinhardt1986epistemic}
    \cite{carlson}) Reinhardt suggested the
    EA-schema
    \[\exists e \forall x ( K(\phi) \leftrightarrow x\in W_e)\]
    as a formalization of the mechanicalness of the knower. Here, $W_e$
    is the $e$th computably enumerable set of natural numbers ($W_e$ can also
    be thought of as the set of naturals enumerated by the $e$th Turing machine).
    For simplicity, consider the case where $x$ is the lone free variable
    of $\phi$. Then in terms of Definition \ref{maindefextension}, the schema
    becomes:
    ``If $X$ were commanded to enumerate his knowledge in the language of EA,
    then the set of $n\in\mathbb N$ such that $X$ would include $\phi(x|\overline n)$
    in the resulting list, would be computably enumerable.''
    This is not just plausible but obvious\footnote{What is much less obvious
    is the fact that it is consistent for the knower himself to
    know the schema in question. This was conjectured by Reinhardt, and
    proved by Carlson \cite{carlson} using sophisticated structural
    results about the ordinals \cite{carlson1999}. See
    \cite{alexander2015fast} for an elementary
    proof of a weaker version of the conjecture.}, since $X$ himself
    is an AGI and thus presumably a computer.
\end{example}

\begin{example}
\label{reinhardtnegativeexample}
  (Reinhardt's absolute version of the incompleteness theorem)
  If we vary the formula from Example \ref{smtexample} by requiring that the
  knowing know the value of $e$, we obtain:
  \[
    \exists e K(\forall x ( K(\phi) \leftrightarrow x\in W_e)).
  \]
  Carlson \cite{carlson} glosses this schema in English as:
  ``I am a Turing machine, and I know which one.''
  Reinhardt showed that this schema is \emph{not} consistent with basic
  axioms about knowledge. Following Carlson's gloss, this strongly
  suggests that it is impossible for an AGI to know its own code\footnote{We have
  pointed out elsewhere \cite{alexander2014machine} that Reinhardt
  implicitly assumes that the knower knows its own truthfulness, and that
  it is possible for a knowing machine to know its own code if it is allowed to
  be ignorant of its own truthfulness, despite still being truthful.
  See \cite{aldini2015theory} and \cite{aldini2015self} for some additional discussion.}.
\end{example}

\begin{example}
\label{ectexample}
  (The Epistemic Church's Thesis \cite{flagg1985church} \cite{carlson2016collapsing})
  The following EA-schema has been suggested as a kind of epistemic formalization
  of Church's Thesis:
  \[
  ( \forall x\exists y (K(\phi))  ) \rightarrow
  ( \exists e K( \forall x\exists y ( E(e,x,y) \wedge \phi  )  )  ),
  \]
  where $E(e,x,y)$ is an EA-formula which expresses that the $e$th Turing machine
  outputs $y$ on input $x$.
  This becomes: ``Suppose $X$ were commanded to enumerate his EA-knowledge.
  Assume there is a (not necessarily computable) function
  $f:\mathbb N\to\mathbb N$ such that for every $n\in\mathbb N$,
  $\phi(x|\overline n)(y|\overline{f(n)})$ is included in the resulting enumeration.
  Then in fact there is a \emph{computable}
  function $f':\mathbb N\to\mathbb N$ (with Turing index $e$)
  such that $f'$ has the same property and such that the enumeration includes
  a statement that $f'$ has said property.''
  This beautiful formalism seems to capture the AGI's self-reflection ability.
  We can imagine the AGI dutifully enumerating statement after statement and
  as she goes, she discovers and predicts patterns in her own enumeration.
  Flagg proved that (knowledge by the knower of) the Epistemic Church's Thesis is
  consistent with basic axioms of knowledge \cite{flagg1985church},
  and Carlson proved that it is also consistent with
  Reinhardt's strong mechanistic thesis \cite{carlson2016collapsing}.
\end{example}

\begin{remark}
  As far as we know, AGI has not yet received much attention in the mathematical logical
  literature. Instead, mathematical logicians tend to concern themselves with
  \emph{knowing agents} or \emph{knowing machine}. Presumably, every AGI is a
  knowing agent and a knowing machine, but certainly not every
  knowing agent (or knowing machine) is an AGI. Thus, in general,
  inconsistency results about knowing agents or knowing machines
  carry directly over to AGIs (if no knowing agent, or no knowing machine, can
  satisfy some property, then in particular no AGI can either).
  Consistency results do not generally carry over to AGIs (it may be possible for
  a knowing agent or a knowing machine to satisfy some property, but it might be
  that none of the knowing agents or knowing machines which satisfy that property
  are AGIs). Nevertheless, a positive result about knowing agents or knowing machines
  should at least count as evidence in favor of the corresponding positive result
  for AGIs, at least if there is no clear reason otherwise. In the examples above:
  \begin{itemize}
    \item
    Reinhardt's strong mechanistic thesis (Example \ref{smtexample})
    was proven to be consistent, so it is possible for a knowing machine to
    know that it is a machine (without necessarily knowing which machine).
    Since not every knowing machine is an AGI, it might still be impossible
    for an AGI to know it is a machine. But the consistency of Reinhardt's
    strong mechanistic thesis at least suggests evidence that an AGI can
    know it is a machine.
    \item
    Reinhardt's absolute version of the incompleteness theorem
    (Example \ref{reinhardtnegativeexample}) is an inconsitency result.
    As such, it transfers over directly to AGI, proving (at least under
    suitable idealization) that no AGI can know its own code\footnote{and its
    own truthfulness---we have pointed out \cite{alexander2014machine} that
    Reinhardt implicitly
    assumes the knower knows its own truthfulness.}.
    \item
    The epistemic Church's thesis (Example \ref{ectexample}) was proven to be
    consistent---some knowing machine satisfies it. Since not every knowing
    machine is an AGI, it might still be impossible for an AGI to satisfy
    this consistency result. But at least the result suggests evidence that
    an AGI can know the epistemic Church's thesis about itself.
  \end{itemize}
\end{remark}

\begin{example}
\label{fineexample}
  (Higher-order ignorance) Let $I(\phi)$ be shorthand for
  $\neg K(\phi)\wedge \neg K(\neg\phi)$, so $I(\phi)$ expresses the knower's
  ignorance about $\phi$. Kit Fine argued \cite{fine2018ignorance} that very
  basic assumptions
  about knowledge imply that second-order ignorance implies third-order (and hence
  all higher-than-second-order) ignorance:
  \[
    I(I(\phi)) \rightarrow I(I(I(\phi))).
  \]
  This becomes: ``If, when $X$ is commanded to enumerate his knowledge in the
  language EA (or some similar standard mathematical language with a knowledge
  operator), $X$ would not enumerate either $I(\phi)$ nor $\neg I(\phi)$ in
  the resulting enumeration, then $X$ would also not enumerate either $I(I(\phi))$
  nor $\neg I(I(\phi))$ in the resulting enumeration.''
\end{example}

\begin{example}
  (Belief and higher-order ignorance) Fano and Graziani have suggested \cite{fano} the
  following axiom which would relate belief ($B$) with higher-order ignorance
  (where, as in Example \ref{fineexample}, $I(\phi)$ is shorthand for
  $\neg K(\phi)\wedge \neg K(\neg\phi)$):
  \[
    ((B(\phi) \wedge \neg\phi)\vee (B(\neg\phi)\wedge \phi)) \rightarrow I(I(\phi)),
  \]
  in other words, that false belief about $\phi$ implies higher-order ignorance
  about $\phi$. It would be straightforward to give a definition similar to
  Definition \ref{maindef} for belief, along the following lines: an AGI $X$
  believes a formula $\phi$ (in a standard mathematical language $\mathscr L$)
  if and only if $X$ would include $\phi$ in the resulting list if $X$ were
  commanded:
    ``Enumerate, in the language $\mathscr L$, every sentence,
  expressible in $\mathscr L$, which you believe.''
  This proposed axiom of Fano and Graziani would then become:
  ``If, when commanded to enumerate his beliefs in EA (or similar language),
  $X$ would include $\neg\phi$ (if $\phi$ is true) or $\phi$ (if $\phi$ is false),
  then, when commanded to enumerate his knowledge in said language,
  $X$ would not include $I(\phi)$ nor $\neg I(\phi)$.''
\end{example}

\begin{example}
  (Intuitive Ordinal Intelligence) Fill this in.
\end{example}

\section{Conclusion}
\label{conclusionsection}

What does it mean to know something? This is a difficult question and there probably
is no one true answer. In the field of AGI, how can we systematically investigate
the theoretical properties of knowledge, when different AGIs might not even agree
about what knowledge really means? So motivated, we have proposed
an elegant way to brush these philosophical questions aside. In Definition \ref{maindef},
we declare that an AGI knows a sentence in a standard mathematical language if and
only if that AGI would enumerate that sentence if commanded to enumerate all the
things it knows (according to its own internal knowledge definition) in that
mathematical language. In Definition \ref{maindefextension}
we extend this to formulas with free variables, not just sentences.

This one-size-fits-all knowledge definition sets the study of AGI knowledge
on a firmer theoretical footing. In Section \ref{appsection} we give examples
of how our definition can serve as a bridge to translate knowledge-related
results from mathematical logic into the realm of AGI.

\section*{Acknowledgments}

We gratefully acknowledge Alessandro Aldini and Phil Maguire for
comments and feedback.

\bibliographystyle{splncs04}
\bibliography{short}

\end{document}